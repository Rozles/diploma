{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import ast\n",
    "import os\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from retinaface import RetinaFace\n",
    "from scipy.stats import pearsonr, wasserstein_distance\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "\n",
    "# %matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "import ssl\n",
    "\n",
    "# Disable SSL certificate verification\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open json image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('image_data.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MiDaS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
    "model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
    "#model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n",
    "\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
    "midas_large = torch.hub.load(\"intel-isl/MiDaS\", \"DPT_Large\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "midas.to(device)\n",
    "midas_large.to(device)\n",
    "midas.eval()\n",
    "midas_large.eval()\n",
    "\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "\n",
    "\n",
    "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
    "    transform = midas_transforms.dpt_transform\n",
    "else:\n",
    "    transform = midas_transforms.small_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gauss(sigma):\n",
    "    N = sigma * 3 + 0.5 // 1\n",
    "    rangee = np.linspace(-N, N, num=int(2*N+1), dtype=np.float64)\n",
    "    kernel = 1/(math.sqrt(2 * math.pi) * sigma) * np.exp(-rangee**2/(2*sigma**2))\n",
    "    return (kernel / np.sum(kernel))\n",
    "    \n",
    "def load_images(page):\n",
    "    request = f'https://www.wikiart.org/en/popular-paintings?json=2&page={page}'\n",
    "    response = requests.get(request)\n",
    "    return response.json()['Paintings']\n",
    "\n",
    "def load_images_2(page):\n",
    "    request = f'https://www.wikiart.org/en/popular-paintings?json=1&page={page}'\n",
    "    response = requests.get(request)\n",
    "    return response.json()\n",
    "\n",
    "def painting_detailss_legacy(id):\n",
    "    request = f'http://www.wikiart.org/en/App/Painting/ImageJson/{id}'\n",
    "    response = requests.get(request)\n",
    "    return response.json()\n",
    "\n",
    "def painting_details(id):\n",
    "    request = f'https://www.wikiart.org/en/api/2/Painting?id={id}'\n",
    "    response = requests.get(request)\n",
    "    #check if response is valid\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def popular_artists(page):\n",
    "    request = f'http://www.wikiart.org/en/Popular-Artists/alltime/{page}?json=1&PageSize=100'\n",
    "    response = requests.get(request)\n",
    "    return response.json()\n",
    "\n",
    "def paintings_by_artist(artist_url):\n",
    "    request = f'http://www.wikiart.org/en/App/Painting/PaintingsByArtist?artistUrl={artist_url}&json=2'\n",
    "    response = requests.get(request)\n",
    "    return response.json()\n",
    "\n",
    "def most_popular_paintings(pagination_token=None):\n",
    "    pagination_string = f'?&paginationToken={pagination_token}' if pagination_token is not None else ''\n",
    "    request = f'https://www.wikiart.org/en/api/2/MostViewedPaintings{pagination_string}'\n",
    "    response = requests.get(request)\n",
    "    json_data = response.json()\n",
    "    try:\n",
    "        data = json_data['data']\n",
    "        pagination_token = json_data['paginationToken']\n",
    "        has_more = json_data['hasMore']\n",
    "    except:\n",
    "        data = json_data\n",
    "        pagination_token = None\n",
    "        has_more = False\n",
    "    return data, pagination_token, has_more\n",
    "\n",
    "\n",
    "def dictionaries_by_group_id(id=1):\n",
    "    ## ID:\n",
    "    ## 1: Art Movement\n",
    "    ## 2: Style\n",
    "    ## 3: Genre\n",
    "    ## 4: Technique\n",
    "    ## 7: Painting School or Group\n",
    "    ## 10: Nation\n",
    "    ## 11: Field\n",
    "    request = f'http://www.wikiart.org/en/App/wiki/DictionariesJson/{id}'\n",
    "    response = requests.get(request)\n",
    "    return response.json()\n",
    "\n",
    "def artists_by_dictionary(dictionary, seo_name, page):\n",
    "    request = f'http://www.wikiart.org/en/App/{dictionary}/{seo_name}/{page}?json=1&PageSize=100'\n",
    "    print(request)\n",
    "    response = requests.get(request)\n",
    "    return response\n",
    "\n",
    "def load_image(image):\n",
    "    img =  Image.open(BytesIO(requests.get(image['image']).content))\n",
    "    return img\n",
    "\n",
    "def load_np_image(image):\n",
    "    img =  np.array(Image.open(BytesIO(requests.get(image['image']).content)))\n",
    "    return img\n",
    "\n",
    "def load_np_image_2(image):\n",
    "    url = image['image']\n",
    "    remove = '!Large.jpg'\n",
    "    url = url.replace(remove, '')\n",
    "    img =  np.array(Image.open(BytesIO(requests.get(url).content)))\n",
    "    return img\n",
    "\n",
    "\n",
    "def predict_depth_resize(image):\n",
    "    im_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    input_batch = transform(im_bgr).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = midas(input_batch)\n",
    "\n",
    "    prediction = torch.nn.functional.interpolate(\n",
    "        prediction.unsqueeze(1),\n",
    "        size=im_bgr.shape[:2],\n",
    "        mode=\"bicubic\",\n",
    "        align_corners=False,\n",
    "    ).squeeze()\n",
    "\n",
    "    output = prediction.cpu().numpy()\n",
    "    return output\n",
    "\n",
    "def predict_depth(image):\n",
    "    im_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    input_batch = transform(im_bgr).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = midas(input_batch)\n",
    "\n",
    "    output = prediction.cpu().numpy()\n",
    "    return output.squeeze()\n",
    "\n",
    "def predict_depth_large(image):\n",
    "    im_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    input_batch = transform(im_bgr).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = midas_large(input_batch)\n",
    "\n",
    "    output = prediction.cpu().numpy()\n",
    "    return output.squeeze()\n",
    "\n",
    "def plot_3d(image, depth_map):\n",
    "    if len(image.shape) < 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    if image.shape != depth_map.shape:\n",
    "        image = cv2.resize(image, (depth_map.shape[1], depth_map.shape[0]))\n",
    "    x, y = np.meshgrid(np.arange(image.shape[1]), np.arange(image.shape[0]))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.plot_surface(x, y, depth_map, facecolors=image/255.0, rstride=1, cstride=1, cmap=cm.viridis, linewidth=0, antialiased=False, shade=False)\n",
    "    ax.view_init(azim=70, elev=70)\n",
    "    plt.show()\n",
    "\n",
    "# def plot_3d_scale(image, depth_map):\n",
    "#     if len(image.shape) < 3:\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "#     if image.shape != depth_map.shape:\n",
    "#         image = cv2.resize(image, (depth_map.shape[1], depth_map.shape[0]))\n",
    "#     x, y = np.meshgrid(np.arange(image.shape[1]), np.arange(image.shape[0]))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.gca(projection='3d')\n",
    "#     ax.plot_surface(x, y, depth_map, facecolors=image/255.0, rstride=1, cstride=1, cmap=cm.viridis, linewidth=0, antialiased=False, shade=False)\n",
    "#     ax.view_init(azim=70, elev=70)\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.gca(projection='3d')\n",
    "#     depth_normalized = (depth_map - np.min(depth_map)) / (np.max(depth_map) - np.min(depth_map))\n",
    "#     ax.plot_surface(x, y, depth_map, rstride=1, cstride=1, facecolors=cm.viridis(depth_normalized), linewidth=0, antialiased=False, shade=False)\n",
    "#     ax.view_init(azim=70, elev=70)\n",
    "#     plt.show()\n",
    "\n",
    "def plot_3d_scale(image, depth_map):\n",
    "    if len(image.shape) < 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    if image.shape != depth_map.shape:\n",
    "        image = cv2.resize(image, (depth_map.shape[1], depth_map.shape[0]))\n",
    "\n",
    "    x, y = np.meshgrid(np.arange(image.shape[1]), np.arange(image.shape[0]))\n",
    "\n",
    "    # Create a single figure\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # First subplot\n",
    "    ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax1.plot_surface(y, x, depth_map, facecolors=image/255.0, rstride=1, cstride=1, cmap=cm.viridis, linewidth=0, antialiased=False, shade=False)\n",
    "    ax1.view_init(azim=30, elev=60)\n",
    "\n",
    "    # Second subplot\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    depth_normalized = (depth_map - np.min(depth_map)) / (np.max(depth_map) - np.min(depth_map))\n",
    "    ax2.plot_surface(y, x, depth_map, rstride=1, cstride=1, facecolors=cm.viridis(depth_normalized), linewidth=0, antialiased=False, shade=False)\n",
    "    ax2.view_init(azim=30, elev=60)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and save image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE NA ENKRAT *NE DELA*\n",
    "\n",
    "def build_dataset_old(data_dict, progress_bar, pagination_token=None, paintings_count=0, has_more=True, painting_index=0):   \n",
    "    while has_more:\n",
    "        data, new_token, has_more = most_popular_paintings(pagination_token)\n",
    "    \n",
    "        if 'Exception' in data:\n",
    "            return build_dataset_old(data_dict, progress_bar, pagination_token, paintings_count, True, 0)\n",
    "        else:\n",
    "            pagination_token = new_token\n",
    "\n",
    "        for i in range(painting_index, len(data)):\n",
    "            painting = data[i]\n",
    "            details = painting_details(painting['id'])\n",
    "            if 'Exception' in details:\n",
    "                return build_dataset_old(data_dict, progress_bar, pagination_token, paintings_count, has_more, i)\n",
    "\n",
    "            painting_id = details.pop('id')\n",
    "            data_dict[painting_id] = details\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        paintings_count += len(data)\n",
    "        \n",
    "        if paintings_count > progress_bar.total:\n",
    "            return data_dict, paintings_count\n",
    "        \n",
    "    return data_dict, paintings_count\n",
    "\n",
    "def build_dataset_save(progress_bar, pagination_token=None, painting_index=0):   \n",
    "    has_more=True\n",
    "    data_dict = {}\n",
    "    while has_more:\n",
    "        data, pagination_token, has_more = most_popular_paintings(pagination_token)\n",
    "    \n",
    "        if 'Exception' in data:\n",
    "            return data_dict, pagination_token, 0\n",
    "\n",
    "        for i in range(painting_index, len(data)):\n",
    "            painting = data[i]\n",
    "            details = painting_details(painting['id'])\n",
    "            if 'Exception' in details:\n",
    "                return data_dict, pagination_token, i + 1\n",
    "\n",
    "            painting_id = details.pop('id')\n",
    "            details.pop('description')\n",
    "            data_dict[painting_id] = details\n",
    "            progress_bar.update(1)\n",
    "        \n",
    "    return data_dict, pagination_token, 0\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PO DELIH \n",
    "\n",
    "\n",
    "def build_dataset(progress_bar, pagination_token=None, painting_index=0):   \n",
    "    has_more=True\n",
    "    data_dict = {}\n",
    "    while has_more:\n",
    "        try:\n",
    "            data, pagination_token, has_more = most_popular_paintings(pagination_token)\n",
    "        \n",
    "            if 'Exception' in data:\n",
    "                print('API 1 paintings', data)\n",
    "                return data_dict, pagination_token, 0\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            return data_dict, pagination_token, 0\n",
    "\n",
    "        for i in range(painting_index, len(data)):\n",
    "            painting_index = 0\n",
    "            painting = data[i]\n",
    "            try:\n",
    "                details = painting_details(painting['id'])\n",
    "            except KeyboardInterrupt:\n",
    "                return data_dict, pagination_token, i\n",
    "            \n",
    "            if details == None:\n",
    "                print('Error with painting details', painting)\n",
    "                return data_dict, pagination_token, i\n",
    "            \n",
    "            if 'Exception' in details:\n",
    "                print('API 2 details', details)\n",
    "                return data_dict, pagination_token, i\n",
    "\n",
    "            painting_id = details.pop('id')\n",
    "            details.pop('description')\n",
    "            data_dict[painting_id] = details\n",
    "            progress_bar.update(1)\n",
    "        \n",
    "    return data_dict, pagination_token, 0\n",
    "\n",
    "start_token = 'bj9CuXHXal%2bknEh%2foAMmIuP81uP3rQJss%2fyoYdMOmyapgSx0TJrhCEoNF6VfvUeOm%2bmDw%2fjhd%2f46zsk3PTrRKCn0BZx7khhslEtYt%2bijrsQ%3d'\n",
    "start_index = 38\n",
    "dict_index = 1\n",
    "\n",
    "progress_bar = tqdm()\n",
    "data_dict, token, index  = build_dataset(progress_bar, start_token, start_index)\n",
    "progress_bar.close()\n",
    "\n",
    "print('Token: ', token)\n",
    "print('Index: ', index)\n",
    "print('Length: ', len(data_dict))\n",
    "print('Next dictionary index: ', dict_index + 1)\n",
    "\n",
    "with open(f'data_{dict_index}.json', 'w') as outfile:\n",
    "    json.dump(data_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE DATA\n",
    "\n",
    "with open('all_data.json', 'r') as json_file:\n",
    "    all_data = json.load(json_file)\n",
    "\n",
    "for i in range(1, 5):\n",
    "    file_path = f'data_{i}.json'\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        all_data.update(data)\n",
    "        os.remove(file_path)\n",
    "\n",
    "print(len(all_data))\n",
    "\n",
    "with open('all_data.json', 'w') as outfile:\n",
    "    json.dump(all_data, outfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method with faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST FACE DETECTORS\n",
    "\n",
    "import dlib\n",
    "import face_detection\n",
    "\n",
    "def test_face_detectors(painting):\n",
    "    # check if painting is a dictionary or a path to an image\n",
    "    if isinstance(painting, dict):\n",
    "        image = load_np_image(painting)\n",
    "    else:\n",
    "        image = painting\n",
    "\n",
    "    if image.shape[0] > image.shape[1]:\n",
    "        figsize=(8, 6)\n",
    "        subplot_1 = 2\n",
    "        subplot_2 = 3\n",
    "    else:\n",
    "        figsize=(6, 8)\n",
    "        subplot_1 = 3\n",
    "        subplot_2 = 2\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "\n",
    "    # 1 opencv - haar cascade\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces_cv = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    cv_image = image.copy()\n",
    "    \n",
    "    if len(faces_cv) > 0:\n",
    "        for (x, y, w, h) in faces_cv:\n",
    "            cv2.rectangle(cv_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    plt.subplot(subplot_1, subplot_2, 1)\n",
    "    plt.axis('off')    \n",
    "    plt.imshow(cv_image)\n",
    "    plt.title('Haar cascade - opencv')\n",
    "\n",
    "    # 2 dlib - HOG\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces_dlib = detector(gray, 1)\n",
    "    dlib_image = image.copy()\n",
    "    \n",
    "    if len(faces_dlib) > 0:\n",
    "        for face in faces_dlib:\n",
    "            cv2.rectangle(dlib_image, (face.left(), face.top()), (face.right(), face.bottom()), (0, 255, 0), 2)\n",
    "    plt.subplot(subplot_1, subplot_2, 2)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(dlib_image)\n",
    "    plt.title('HOG - dlib')        \n",
    "    \n",
    "    # 3 face_detection - DSFD\n",
    "    if len(faces_dlib) > 0:\n",
    "        detector = face_detection.build_detector(\"DSFDDetector\", confidence_threshold=.5, nms_iou_threshold=.3)\n",
    "        faces_fd = detector.detect(image)\n",
    "    else:\n",
    "        faces_fd = []\n",
    "    fd_image = image.copy()\n",
    "\n",
    "    if len(faces_fd) > 0:\n",
    "        for face in faces_fd:\n",
    "            x1, y1, x2, y2 = int(face[0]), int(face[1]), int(face[2]), int(face[3])\n",
    "            cv2.rectangle(fd_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    plt.subplot(subplot_1, subplot_2, 3)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(fd_image)\n",
    "    plt.title('DSFD - face_detection')\n",
    "   \n",
    "    #4 dnn caffe\n",
    "    face_net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt.txt\", \"res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    face_net.setInput(blob)\n",
    "    faces_caffe = face_net.forward()\n",
    "    caffe_image = image.copy()\n",
    "    h, w = caffe_image.shape[:2]\n",
    "    if len(faces_caffe) > 0:\n",
    "        for i in range(0, faces_caffe.shape[2]):\n",
    "            confidence = faces_caffe[0, 0, i, 2]\n",
    "            if confidence > 0.5:\n",
    "                box = faces_caffe[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                cv2.rectangle(caffe_image, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "    plt.subplot(subplot_1, subplot_2, 4)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(caffe_image)\n",
    "    plt.title('SSD - caffe')\n",
    "\n",
    "\n",
    "    #5 dlib cnn\n",
    "    cnn_face_detector = dlib.cnn_face_detection_model_v1('mmod_human_face_detector.dat')\n",
    "    faces_dlib_cnn = cnn_face_detector(image, 1)\n",
    "    dlib_cnn_image = image.copy()\n",
    "    \n",
    "    if len(faces_dlib_cnn) > 0:\n",
    "        for face in faces_dlib_cnn:\n",
    "            x, y, w, h = face.rect.left(), face.rect.top(), face.rect.right(), face.rect.bottom()\n",
    "            cv2.rectangle(dlib_cnn_image, (x, y), (w, h), (0, 255, 0), 2)\n",
    "    plt.subplot(subplot_1, subplot_2, 5)  \n",
    "    plt.axis('off')  \n",
    "    plt.imshow(dlib_cnn_image)\n",
    "    plt.title('MMOD CNN - dlib')\n",
    "\n",
    "    # 6 retinaface\n",
    "    if image.shape[2] == 4:\n",
    "        image = image[:, :, :3]\n",
    "        \n",
    "    faces_rf = RetinaFace.detect_faces(image)\n",
    "    rf_image = image.copy()\n",
    "    \n",
    "    if faces_rf:\n",
    "        for face in faces_rf:  \n",
    "            if len(face) == 0:\n",
    "                break\n",
    "            x1, y1, x2, y2 = faces_rf[face]['facial_area'][0], faces_rf[face]['facial_area'][1], faces_rf[face]['facial_area'][2], faces_rf[face]['facial_area'][3]\n",
    "            cv2.rectangle(rf_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    plt.subplot(subplot_1, subplot_2, 6)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(rf_image)\n",
    "    plt.title('RetinaFace')\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.tight_layout() \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examples for different face detectors\n",
    "\n",
    "with open('image_data.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "    print(data['5772700bedc2cb3880bc7d83'])\n",
    "    test_face_detectors(data['5772700bedc2cb3880bc7d83'])\n",
    "    print(data['577277e1edc2cb3880d61b82'])\n",
    "    test_face_detectors(data['577277e1edc2cb3880d61b82'])\n",
    "    #test_face_detectors(data['577286a0edc2cb388004d4d9'])\n",
    "    #test_face_detectors(data['57727ab6edc2cb3880df967a'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for first method\n",
    "\n",
    "def  fit_plane(x, y, z, plot=False):\n",
    "    A = np.column_stack((x, y, np.ones_like(x)))\n",
    "    coefficients, residuals, _, _ = np.linalg.lstsq(A, z, rcond=None)\n",
    "    a, b, c = coefficients\n",
    "    normal = np.array([a, b, -1]) / np.linalg.norm(np.array([a, b, -1]))\n",
    "    normal_z0 = np.array([0, 0, 1])\n",
    "    angle = np.arccos(np.abs(np.dot(normal, normal_z0)))\n",
    "    if plot:\n",
    "        xx, yy = np.meshgrid(np.arange(0, 1, 0.1), np.arange(0, 1, 0.1))\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca(projection='3d')\n",
    "        ax.scatter(x, y, z, c='r', s=100)\n",
    "        ax.plot_surface(xx, yy, a * xx + b * yy + c, alpha=0.5)\n",
    "        ax.view_init(azim=70, elev=70)\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    return angle, np.degrees(angle), a, b, c\n",
    "\n",
    "def fit_plane_with_faces(image, plot=False):\n",
    "    f = 17 #mm\n",
    "    sensor_height = 32 #mm\n",
    "    face_height = 185 #mm\n",
    "    faces_rf = RetinaFace.detect_faces(image)\n",
    "    points_x = []\n",
    "    points_y = []\n",
    "    points_z = []\n",
    "    \n",
    "    copy = image.copy()\n",
    "\n",
    "    for i, face in enumerate(faces_rf):  \n",
    "        if len(face) == 0:\n",
    "            break\n",
    "        x1, y1, x2, y2 = faces_rf[face]['facial_area'][0], faces_rf[face]['facial_area'][1], faces_rf[face]['facial_area'][2], faces_rf[face]['facial_area'][3]\n",
    "        face_height_px = y2 - y1\n",
    "        image_height = image.shape[0]\n",
    "        d = (f * face_height * image_height) / (face_height_px * sensor_height)\n",
    "        points_x.append((x1+x2)/2)\n",
    "        points_y.append((y1+y2)/2)\n",
    "        points_z.append(d)\n",
    "        \n",
    "        if plot:\n",
    "            copy = cv2.rectangle(copy, (x1, y1), (x2, y2), (0, 255 / len(faces_rf) * (i + 1), 0), 2)\n",
    "    if len(points_x) == 0:\n",
    "        return -1, -1\n",
    "    \n",
    "    if plot:\n",
    "        plt.imshow(copy)\n",
    "        plt.show()\n",
    "    \n",
    "    # normalize points \n",
    "    points_x = np.array(points_x) / image.shape[1]\n",
    "    points_y = np.array(points_y) / image.shape[0]\n",
    "    points_z = np.max(points_z) - np.array(points_z) # rotate coordinate system\n",
    "    points_z = (points_z - np.mean(points_z)) / np.std(points_z) # normalize\n",
    "    \n",
    "    angle, angle_deg, a, b, c = fit_plane(points_x, points_y, points_z, plot)\n",
    "    \n",
    "    return angle, angle_deg, a, b, c\n",
    "\n",
    "def compare_faces_wtih_depth(image, plot=False):\n",
    "    f = 17 #mm\n",
    "    sensor_height = 32 #mm\n",
    "    face_height = 185 #mm\n",
    "    faces_rf = RetinaFace.detect_faces(image)\n",
    "    print(faces_rf)\n",
    "    points_x = []\n",
    "    points_y = []\n",
    "    points_z = []\n",
    "    \n",
    "    copy = image.copy()\n",
    "\n",
    "    for i, face in enumerate(faces_rf):  \n",
    "        if len(face) == 0:\n",
    "            break\n",
    "        x1, y1, x2, y2 = faces_rf[face]['facial_area'][0], faces_rf[face]['facial_area'][1], faces_rf[face]['facial_area'][2], faces_rf[face]['facial_area'][3]\n",
    "        face_height_px = y2 - y1\n",
    "        image_height = image.shape[0]\n",
    "        d = (f * face_height * image_height) / (face_height_px * sensor_height)\n",
    "        points_x.append((x1+x2)/2)\n",
    "        points_y.append((y1+y2)/2)\n",
    "        points_z.append(d)\n",
    "        \n",
    "        if plot:\n",
    "            copy = cv2.rectangle(copy, (x1, y1), (x2, y2), (0, 255 / len(faces_rf) * (i + 1), 0), 2)\n",
    "    if len(points_x) == 0:\n",
    "        return -1, -1\n",
    "    if plot:\n",
    "        plt.imshow(copy)\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "    depth_map = predict_depth(image)\n",
    "    x_factor = depth_map.shape[1] / image.shape[1]\n",
    "    y_factor = depth_map.shape[0] / image.shape[0]\n",
    "    depth_map_x = np.array(points_x) * x_factor\n",
    "    depth_map_y = np.array(points_y) * y_factor\n",
    "    depth_map_z = np.zeros_like(points_z)\n",
    "    \n",
    "    # normalize points \n",
    "    points_x = np.array(points_x) / image.shape[1]\n",
    "    points_y = np.array(points_y) / image.shape[0]\n",
    "    points_z = np.max(points_z) - np.array(points_z) # rotate coordinate system\n",
    "    points_z = (points_z - np.mean(points_z)) / np.std(points_z) # normalize\n",
    "\n",
    "\n",
    "    x, y = np.meshgrid(np.arange(depth_map.shape[1]), np.arange(depth_map.shape[0]))\n",
    "    for i in range(len(points_z)):\n",
    "        x_i = x[np.where(np.sqrt((x - depth_map_x[i])**2 + (y - depth_map_y[i])**2) < 10)] \n",
    "        y_i = y[np.where(np.sqrt((x - depth_map_x[i])**2 + (y - depth_map_y[i])**2) < 10)]\n",
    "        dist = np.mean(depth_map[y_i, x_i])\n",
    "        depth_map_z[i] = dist\n",
    "   \n",
    "   \n",
    "    if (plot):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca(projection='3d')\n",
    "        ax.plot_surface(x, y, depth_map, cmap=cm.viridis, linewidth=0, antialiased=False, alpha=0.5)\n",
    "        colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "        ax.scatter(depth_map_x, depth_map_y, depth_map_z, c=colors[:len(depth_map_x)], s=100)\n",
    "        ax.view_init(azim=70, elev=70)\n",
    "        plt.show()\n",
    "\n",
    "    depth_map_z = (depth_map_z - np.mean(depth_map_z)) / np.std(depth_map_z) # normalize\n",
    "\n",
    "    mse = np.sum(np.square(points_z - depth_map_z)) / len(points_z)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    return mse, rmse\n",
    "\n",
    "# THIS IS THE FUNCTION THAT WAS USED TO CALCULATE THE DEPTH OF THE FACES IN THE PAINTINGS\n",
    "def find_depth_faces(painting):\n",
    "    f = 17 #mm\n",
    "    sensor_height = 32 #mm\n",
    "    face_height = 185 #mm\n",
    "    retinaface = ast.literal_eval(painting['retinaface'])\n",
    "    \n",
    "    if len(retinaface) == 0:\n",
    "        return painting\n",
    "    \n",
    "    points_x = []\n",
    "    points_y = []\n",
    "    points_z = []\n",
    "\n",
    "    # image = load_np_image(painting)\n",
    "\n",
    "    for face_id in retinaface:\n",
    "        face = retinaface[face_id]\n",
    "        landmarks = face['landmarks']\n",
    "        eyes = np.add(landmarks['right_eye'], landmarks['left_eye']) / 2\n",
    "        mouth = np.add(landmarks['mouth_left'], landmarks['mouth_right']) / 2\n",
    "        dist = np.sqrt((eyes[0] - mouth[0])**2 + (eyes[1] - mouth[1])**2)\n",
    "        face_height_px = dist * 3\n",
    "        image_height = painting['height']\n",
    "        d = (f * face_height * image_height) / (face_height_px * sensor_height)\n",
    "        x1, y1, x2, y2 = face['facial_area'][0], face['facial_area'][1], face['facial_area'][2], face['facial_area'][3]\n",
    "        points_x.append((x1 + x2) / 2)\n",
    "        points_y.append((y1 + y2) /2)\n",
    "        points_z.append(d)\n",
    "\n",
    "        # face_height_box = y2 - y1\n",
    "        # d2 = (f * face_height * image_height) / (face_height_box * sensor_height)\n",
    "        ## draw points\n",
    "        #diff_vector = eyes - mouth\n",
    "        #image = cv2.circle(image, (int(eyes[0]), int(eyes[1])), 5, (0, 0, 255), -1)\n",
    "        #image = cv2.circle(image, (int(mouth[0]), int(mouth[1])), 5, (255, 0, 0), -1)\n",
    "        #image = cv2.circle(image, (int(eyes[0] + 1.5 * diff_vector[0]), int(eyes[1] + 1.5* diff_vector[1])), 5, (0, 255, 255), -1)\n",
    "        #image = cv2.circle(image, (int(eyes[0] - 1.5 * diff_vector[0]), int(eyes[1] - 1.5 * diff_vector[1])), 5, (0, 255, 255), -1)\n",
    "\n",
    "        ## draw bounding box\n",
    "        #image = cv2.rectangle(image, (face['facial_area'][0], face['facial_area'][1]), (face['facial_area'][2], face['facial_area'][3]), (0, 255, 0), 2)\n",
    "\n",
    "        ## write text\n",
    "        #image = cv2.putText(image, str(round(d, 2)), (int(eyes[0]), int(eyes[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        #image = cv2.putText(image, str(round(d2, 2)), (int(eyes[0]), int(eyes[1]) + 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    # plt.imshow(image)\n",
    "    # plt.show()\n",
    "\n",
    "    ## NORMALIZE\n",
    "\n",
    "    points_x = np.array(points_x) / painting['width']\n",
    "    points_y = np.array(points_y) / painting['height']\n",
    "    points_z = np.max(points_z) - np.array(points_z) \n",
    "    points_z = (points_z - np.mean(points_z)) / np.std(points_z)\n",
    "    angle, angle_deg, a, b, c = fit_plane(points_x, points_y, points_z)\n",
    "    painting['face_plane'] = {\n",
    "        'angle': angle,\n",
    "        'angle_deg': angle_deg,\n",
    "        'a': a,\n",
    "        'b': b,\n",
    "        'c': c\n",
    "    }\n",
    "    return painting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit plane with faces and save results\n",
    "\n",
    "with open('all_data_new_2.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "for id_ in data:\n",
    "    if 'face_plane' in data[id_]:\n",
    "        continue\n",
    "    data[id_] = find_depth_faces(data[id_])\n",
    "\n",
    "with open('all_data_new_2.json', 'w') as outfile:\n",
    "    json.dump(data, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering BY FACE PLANE\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "with open('image_data.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "df_paintings = {}\n",
    "for id_ in data:\n",
    "    retina_face = ast.literal_eval(data[id_]['retinaface'])\n",
    "    if 'face_plane' in data[id_] and len(retina_face) >= 2:\n",
    "        attributes = data[id_]['face_plane']\n",
    "        attributes['title'] = data[id_]['title']\n",
    "        attributes['artist'] = data[id_]['artistName']\n",
    "        if 'completitionYear' in data[id_]:\n",
    "            attributes['year'] = data[id_]['completitionYear']\n",
    "        df_paintings[id_] = attributes\n",
    "\n",
    "# BUILD A DATAFRAME\n",
    "\n",
    "df = pd.DataFrame.from_dict(df_paintings, orient='index')\n",
    "\n",
    "# replace NaN values \n",
    "df = df.fillna(-1)\n",
    "\n",
    "# remove rows with NaN values\n",
    "#df = df.dropna()\n",
    "\n",
    "# only rows with NaN values\n",
    "#df = df[df.isna().any(axis=1)]\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit plane to face data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT faces and plane\n",
    "\n",
    "def plot_faces(painting):\n",
    "    f = 17 #mm\n",
    "    sensor_height = 32 #mm\n",
    "    face_height = 185 #mm\n",
    "\n",
    "    image = load_np_image(painting)\n",
    "   \n",
    "    retinaface = ast.literal_eval(painting['retinaface'])\n",
    "    \n",
    "    points_x = []\n",
    "    points_y = []\n",
    "    points_z = []\n",
    "\n",
    "    # image = load_np_image(painting)\n",
    "\n",
    "    for face_id in retinaface:\n",
    "        face = retinaface[face_id]\n",
    "        landmarks = face['landmarks']\n",
    "        eyes = np.add(landmarks['right_eye'], landmarks['left_eye']) / 2\n",
    "        mouth = np.add(landmarks['mouth_left'], landmarks['mouth_right']) / 2\n",
    "        dist = np.sqrt((eyes[0] - mouth[0])**2 + (eyes[1] - mouth[1])**2)\n",
    "        face_height_px = dist * 3\n",
    "        image_height = painting['height']\n",
    "        d = (f * face_height * image_height) / (face_height_px * sensor_height)\n",
    "        x1, y1, x2, y2 = face['facial_area'][0], face['facial_area'][1], face['facial_area'][2], face['facial_area'][3]\n",
    "        points_x.append((x1 + x2) / 2)\n",
    "        points_y.append((y1 + y2) /2)\n",
    "        points_z.append(d)\n",
    "       \n",
    "    ## NORMALIZE\n",
    "\n",
    "    points_x = np.array(points_x) / painting['width']\n",
    "    points_y = np.array(points_y) / painting['height']\n",
    "    points_z = np.max(points_z) - np.array(points_z) \n",
    "    points_z = (points_z - np.mean(points_z)) / np.std(points_z)\n",
    "\n",
    "    color_z = points_z + np.abs(np.min(points_z))\n",
    "    color_z = color_z / np.max(color_z)\n",
    "    \n",
    "    colormap_name = 'cool'\n",
    "    cmap = plt.cm.get_cmap(colormap_name)\n",
    "\n",
    "    # draw rectangles\n",
    "    copy = image.copy()\n",
    "    for i, face_id in enumerate(retinaface):\n",
    "        face = retinaface[face_id]\n",
    "        x1, y1, x2, y2 = face['facial_area'][0], face['facial_area'][1], face['facial_area'][2], face['facial_area'][3]\n",
    "        \n",
    "        color = cmap(color_z[i])\n",
    "        copy = cv2.rectangle(copy, (x1, y1), (x2, y2), (color[0] *255, color[1] *255, color[2] *255), 2)\n",
    "    \n",
    "    plt.imshow(copy)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.show()\n",
    "\n",
    "    a,b,c = painting['face_plane']['a'], painting['face_plane']['b'], painting['face_plane']['c']\n",
    "    x, y = x, y = np.meshgrid(np.arange(0, 1, 1/image.shape[1]), np.arange(0, 1, 1/ image.shape[0]))\n",
    "    zr = a*x + b*y + c\n",
    "    zr = zr * -1\n",
    "    z0 = np.zeros_like(zr)\n",
    "\n",
    "    z_bottom = np.where(z0 < zr, z0, np.nan)\n",
    "    z_top = np.where(z0 > zr, z0, np.nan)\n",
    "\n",
    "    size_z = points_z + np.abs(np.min(points_z))\n",
    "    size_z = (np.max(size_z) - size_z + 1) * 20\n",
    "   \n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ## Plane\n",
    "    ax.plot_surface(y, x, z_bottom, alpha=0.25, color='gray') \n",
    "    ax.plot_surface(y, x, zr, alpha=0.25, color='mediumspringgreen') \n",
    "    ax.plot_surface(y, x, z_top, alpha=0.25, color='gray') \n",
    "    ## Points\n",
    "    plot = ax.scatter(points_y, points_x, points_z, c=points_z, alpha=1.0, cmap=colormap_name)\n",
    "    ax.set_xlabel('Y')\n",
    "    ax.set_ylabel('X')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.invert_zaxis()\n",
    "    #ax.view_init(azim=0, elev=70)\n",
    "    fig.colorbar(plot)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_results(image, points_x, points_y, points_z, a, b, c):\n",
    "    x, y = np.meshgrid(np.arange(0, 1, 1/image.shape[1]), np.arange(0, 1, 1/ image.shape[0]))\n",
    "    x = np.flip(x)\n",
    "    zr = a*x + b*y + c\n",
    "    z0 = np.zeros_like(zr)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ## Plane\n",
    "    ax.plot_surface(x, y, zr, alpha=2.0, color='o') \n",
    "    ## Points\n",
    "    ax.scatter(points_x, points_y, points_z, c=points_z, alpha=0.1, cmap='Wistia')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    #ax.view_init(azim=70, elev=70)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "count = 0\n",
    "for id_ in data:\n",
    "    if count > 10:\n",
    "        break\n",
    "    painting = data[id_]\n",
    "    retinaface = ast.literal_eval(painting['retinaface'])\n",
    "    if len(retinaface) == 7:\n",
    "            print(painting)\n",
    "            print(painting['retinaface'])\n",
    "            plot_faces(painting)\n",
    "            count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MiDaS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MiDaS - model comparison\n",
    "\n",
    "def compare_midas_models(painting):\n",
    "    print(painting['title'], painting['artistName'], painting['completitionYear'])\n",
    "\n",
    "    image = load_np_image(painting)\n",
    "    depth_map = predict_depth(image)\n",
    "    depth_map_large = predict_depth_large(image)\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.xticks([]) \n",
    "    plt.yticks([]) \n",
    "    plt.title('Original')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(depth_map)\n",
    "    plt.xticks([])  \n",
    "    plt.yticks([])  \n",
    "    plt.title('MiDaS hybrid')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(depth_map_large)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('MiDaS large')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MiDaS - model comparison\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "with open('image_data.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Create an Output widget\n",
    "out = widgets.Output(layout={'border': '1px solid black', 'width': '500px', 'height': '500px', 'overflow': 'scroll'})\n",
    "\n",
    "counter = 0\n",
    "key_list = list(data.keys())\n",
    "#with out:\n",
    "for i in range(0, 100, 1):\n",
    "    id_ = key_list[i]\n",
    "    painting = data[id_]\n",
    "    compare_midas_models(painting)\n",
    "\n",
    "#display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shrink depth maps to 100x100 and convert to float32\n",
    "\n",
    "with open('image_data.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "for id_ in data:\n",
    "    depth_map = np.load(f'depth_maps/{id_}.npy')\n",
    "    depth_map = (depth_map / 255.0).astype(np.float32)\n",
    "    depth_map = cv2.resize(depth_map, (100, 100))\n",
    "    np.save(f'depth_maps_100/{id_}.npy', depth_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 3d image and plot\n",
    "\n",
    "with open('image_data.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Create an Output widget\n",
    "#out = widgets.Output(layout={'border': '1px solid black', 'width': '500px', 'height': '500px', 'overflow': 'scroll'})\n",
    "\n",
    "counter = 0\n",
    "key_list = list(data.keys())\n",
    "#with out:\n",
    "for i in range(0, len(data), 1):\n",
    "    id_ = key_list[i]\n",
    "    painting = data[id_]\n",
    "\n",
    "    if 'fallen angel' in painting['title'].lower():\n",
    "        print(painting)\n",
    "        image = load_np_image(painting)\n",
    "        depth_map = predict_depth(image)\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image)\n",
    "        plt.yticks([])\n",
    "        plt.xticks([])\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(depth_map)\n",
    "        plt.yticks([])\n",
    "        plt.xticks([])\n",
    "        plt.show()\n",
    "\n",
    "        #plot_3d(image, depth_map)\n",
    "        plot_3d_scale(image, depth_map)\n",
    "        \n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering and showcase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE IMAGES WITH DIFFERENT DEPTH MAPS\n",
    "\n",
    "def plot_distances(id_):\n",
    "    with open('image_data.json', 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    \n",
    "    depth_map_1 = np.load(f'depth_maps_100/{id_}.npy')\n",
    "\n",
    "    bar = tqdm(total=len(data))\n",
    "    # EUCLEDIAN DISTANCE\n",
    "    lowest_eucled = 99999999999999999\n",
    "    lowest_eucled_id = None\n",
    "\n",
    "    # MANHATTAN DISTANCE\n",
    "    lowest_manhattan = 99999999999999999\n",
    "    lowest_manhattan_id = None\n",
    "\n",
    "    # CORRELATION COEFFICIENT\n",
    "    correlation_coefficient = -1\n",
    "    correlation_coefficient_id = None\n",
    "\n",
    "    # STRUCTURAL SIMILARITY\n",
    "    structural_similarity = -1\n",
    "    structural_similarity_id = None\n",
    "\n",
    "    # JACCARD SIMILARITY\n",
    "    jaccard_similarity = 0\n",
    "    jaccard_similarity_id = None\n",
    "\n",
    "    # WASSERSTEIN DISTANCE - EMD\n",
    "    wasserstein_dist = 99999999999999999\n",
    "    wasserstein_dist_id = None\n",
    "    \n",
    "    # COSINE SIMILARITY\n",
    "    cosine_similarity = -1\n",
    "    cosine_similarity_id = None\n",
    "\n",
    "\n",
    "    for id_2 in data:\n",
    "\n",
    "        bar.update(1)\n",
    "        if id_ == id_2:\n",
    "            continue\n",
    "        \n",
    "        depth_map_2 = np.load(f'depth_maps_100/{id_2}.npy')\n",
    "        \n",
    "        # EUCLEDIAN DISTANCE\n",
    "        eucled = np.sqrt(np.sum((depth_map_1 - depth_map_2)**2))\n",
    "        if eucled < lowest_eucled:\n",
    "            lowest_eucled = eucled\n",
    "            lowest_eucled_id = id_2\n",
    "\n",
    "        # MANHATTAN DISTANCE\n",
    "        manhattan = np.sum(np.abs(depth_map_1 - depth_map_2))\n",
    "        if manhattan < lowest_manhattan:\n",
    "            lowest_manhattan = manhattan\n",
    "            lowest_manhattan_id = id_2\n",
    "\n",
    "        # CORRELATION COEFFICIENT\n",
    "        cc = pearsonr(depth_map_1.flatten(), depth_map_2.flatten())[0]\n",
    "        if cc > correlation_coefficient:\n",
    "            correlation_coefficient = cc\n",
    "            correlation_coefficient_id = id_2\n",
    "\n",
    "        # STRUCTURAL SIMILARITY\n",
    "        ss = ssim(depth_map_1, depth_map_2, data_range=255)\n",
    "        if ss > structural_similarity:\n",
    "            structural_similarity = ss\n",
    "            structural_similarity_id = id_2\n",
    "\n",
    "        # JACCARD SIMILARITY\n",
    "        threshold_1 = np.mean(depth_map_1)\n",
    "        threshold_2 = np.mean(depth_map_2)\n",
    "        _, binary_1 = cv2.threshold(depth_map_1, threshold_1, 255, cv2.THRESH_BINARY)\n",
    "        _, binary_2 = cv2.threshold(depth_map_2, threshold_2, 255, cv2.THRESH_BINARY)\n",
    "        intersection = np.logical_and(binary_1, binary_2)\n",
    "        union = np.logical_or(binary_1, binary_2)\n",
    "        jaccard = intersection.sum() / union.sum()\n",
    "        if jaccard > jaccard_similarity:\n",
    "            jaccard_similarity = jaccard\n",
    "            jaccard_similarity_id = id_2\n",
    "\n",
    "        # WASSERSTEIN DISTANCE - EMD\n",
    "        wasserstein = wasserstein_distance(depth_map_1.flatten(), depth_map_2.flatten())\n",
    "        if wasserstein < wasserstein_dist:\n",
    "            wasserstein_dist = wasserstein\n",
    "            wasserstein_dist_id = id_2\n",
    "\n",
    "        # COSINE SIMILARITY\n",
    "        cosine = np.dot(depth_map_1.flatten(), depth_map_2.flatten()) / (np.linalg.norm(depth_map_1.flatten()) * np.linalg.norm(depth_map_2.flatten())) \n",
    "        if cosine > cosine_similarity:\n",
    "            cosine_similarity = cosine\n",
    "            cosine_similarity_id = id_2\n",
    "\n",
    "    # plot results\n",
    "    plt.figure(figsize=(5, 10))\n",
    "    plt.subplot(4, 2, 1)\n",
    "    plt.imshow(load_np_image(data[id_]))\n",
    "    plt.title(data[id_]['title'], wrap=True)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 2)\n",
    "    plt.imshow(np.load(f'depth_maps/{id_}.npy'))\n",
    "    plt.title('Original')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 3)\n",
    "    plt.imshow(load_np_image(data[lowest_eucled_id]))\n",
    "    plt.title(data[lowest_eucled_id]['title'], wrap=True)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 4)\n",
    "    plt.imshow(np.load(f'depth_maps/{lowest_eucled_id}.npy'))\n",
    "    plt.title(f'eucled: {lowest_eucled:.2f}')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 5)\n",
    "    plt.imshow(load_np_image(data[lowest_manhattan_id]))\n",
    "    plt.title(data[lowest_manhattan_id]['title'], wrap=True)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 6)\n",
    "    plt.imshow(np.load(f'depth_maps/{lowest_manhattan_id}.npy'))\n",
    "    plt.title(f'manhattan: {lowest_manhattan:.2f}')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 7)\n",
    "    plt.imshow(load_np_image(data[correlation_coefficient_id]))\n",
    "    plt.title(data[correlation_coefficient_id]['title'], wrap=True)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 8)\n",
    "    plt.imshow(np.load(f'depth_maps/{correlation_coefficient_id}.npy'))\n",
    "    plt.title(f'r: {correlation_coefficient:.2f}')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.show() \n",
    "    \n",
    "    plt.figure(figsize=(5, 10))\n",
    "    plt.subplot(4, 2, 1)\n",
    "    plt.imshow(load_np_image(data[structural_similarity_id]))\n",
    "    plt.title(data[structural_similarity_id]['title'], wrap=True)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 2)\n",
    "    plt.imshow(np.load(f'depth_maps/{structural_similarity_id}.npy'))\n",
    "    plt.title(f'SSIM: {structural_similarity:.2f}')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 3)\n",
    "    plt.imshow(load_np_image(data[jaccard_similarity_id]))\n",
    "    plt.title(data[jaccard_similarity_id]['title'], wrap=True)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 4)\n",
    "    plt.imshow(np.load(f'depth_maps/{jaccard_similarity_id}.npy'))\n",
    "    plt.title(f'J: {jaccard_similarity:.2f}')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 5)\n",
    "    plt.imshow(load_np_image(data[wasserstein_dist_id]))\n",
    "    plt.title(data[wasserstein_dist_id]['title'], wrap=True)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 6)\n",
    "    plt.imshow(np.load(f'depth_maps/{wasserstein_dist_id}.npy'))\n",
    "    plt.title(f'WD: {wasserstein_dist:.2f}')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 7)\n",
    "    plt.imshow(load_np_image(data[cosine_similarity_id]))\n",
    "    plt.title(data[cosine_similarity_id]['title'], wrap=True)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 8)\n",
    "    plt.imshow(np.load(f'depth_maps/{cosine_similarity_id}.npy'))\n",
    "    plt.title(f'CSIM: {cosine_similarity:.2f}')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.show()      \n",
    "\n",
    "    bar.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_distances(id_):\n",
    "    with open('image_data.json', 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    \n",
    "    depth_map_1 = np.load(f'depth_maps_100/{id_}.npy')\n",
    "\n",
    "    bar = tqdm(total=len(data))\n",
    "    # EUCLEDIAN DISTANCE\n",
    "    lowest_eucled = 99999999999999999\n",
    "    lowest_eucled_id = None\n",
    "\n",
    "    # MANHATTAN DISTANCE\n",
    "    lowest_manhattan = 99999999999999999\n",
    "    lowest_manhattan_id = None\n",
    "\n",
    "    # CORRELATION COEFFICIENT\n",
    "    correlation_coefficient = -1\n",
    "    correlation_coefficient_id = None\n",
    "\n",
    "    # STRUCTURAL SIMILARITY\n",
    "    structural_similarity = -1\n",
    "    structural_similarity_id = None\n",
    "\n",
    "    # JACCARD SIMILARITY\n",
    "    jaccard_similarity = 0\n",
    "    jaccard_similarity_id = None\n",
    "\n",
    "    # WASSERSTEIN DISTANCE - EMD\n",
    "    wasserstein_dist = 99999999999999999\n",
    "    wasserstein_dist_id = None\n",
    "    \n",
    "    # COSINE SIMILARITY\n",
    "    cosine_similarity = -1\n",
    "    cosine_similarity_id = None\n",
    "\n",
    "\n",
    "    for id_2 in data:\n",
    "\n",
    "        bar.update(1)\n",
    "        if id_ == id_2:\n",
    "            continue\n",
    "        \n",
    "        depth_map_2 = np.load(f'depth_maps_100/{id_2}.npy')\n",
    "        \n",
    "        # EUCLEDIAN DISTANCE\n",
    "        eucled = np.sqrt(np.sum((depth_map_1 - depth_map_2)**2))\n",
    "        if eucled < lowest_eucled:\n",
    "            lowest_eucled = eucled\n",
    "            lowest_eucled_id = id_2\n",
    "\n",
    "        # MANHATTAN DISTANCE\n",
    "        manhattan = np.sum(np.abs(depth_map_1 - depth_map_2))\n",
    "        if manhattan < lowest_manhattan:\n",
    "            lowest_manhattan = manhattan\n",
    "            lowest_manhattan_id = id_2\n",
    "\n",
    "        # CORRELATION COEFFICIENT\n",
    "        cc = pearsonr(depth_map_1.flatten(), depth_map_2.flatten())[0]\n",
    "        if cc > correlation_coefficient:\n",
    "            correlation_coefficient = cc\n",
    "            correlation_coefficient_id = id_2\n",
    "\n",
    "        # STRUCTURAL SIMILARITY\n",
    "        ss = ssim(depth_map_1, depth_map_2, data_range=1)\n",
    "        if ss > structural_similarity:\n",
    "            structural_similarity = ss\n",
    "            structural_similarity_id = id_2\n",
    "\n",
    "        # JACCARD SIMILARITY\n",
    "        threshold_1 = np.mean(depth_map_1)\n",
    "        threshold_2 = np.mean(depth_map_2)\n",
    "        _, binary_1 = cv2.threshold(depth_map_1, threshold_1, 255, cv2.THRESH_BINARY)\n",
    "        _, binary_2 = cv2.threshold(depth_map_2, threshold_2, 255, cv2.THRESH_BINARY)\n",
    "        intersection = np.logical_and(binary_1, binary_2)\n",
    "        union = np.logical_or(binary_1, binary_2)\n",
    "        jaccard = intersection.sum() / union.sum()\n",
    "        if jaccard > jaccard_similarity:\n",
    "            jaccard_similarity = jaccard\n",
    "            jaccard_similarity_id = id_2\n",
    "\n",
    "        # WASSERSTEIN DISTANCE - EMD\n",
    "        wasserstein = wasserstein_distance(depth_map_1.flatten(), depth_map_2.flatten())\n",
    "        if wasserstein < wasserstein_dist:\n",
    "            wasserstein_dist = wasserstein\n",
    "            wasserstein_dist_id = id_2\n",
    "\n",
    "        # COSINE SIMILARITY\n",
    "        cosine = np.dot(depth_map_1.flatten(), depth_map_2.flatten()) / (np.linalg.norm(depth_map_1.flatten()) * np.linalg.norm(depth_map_2.flatten())) \n",
    "        if cosine > cosine_similarity:\n",
    "            cosine_similarity = cosine\n",
    "            cosine_similarity_id = id_2\n",
    "\n",
    "    # plot results\n",
    "    plt.figure(figsize=(5, 8))\n",
    "    plt.subplot(4, 2, 1)\n",
    "    plt.imshow(load_np_image(data[id_]))\n",
    "    plt.title(data[id_]['title'], wrap=True)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 2)\n",
    "    plt.imshow(np.load(f'depth_maps/{id_}.npy'))\n",
    "    plt.title('Original')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 3)\n",
    "    plt.imshow(load_np_image(data[lowest_eucled_id]))\n",
    "    plt.title(data[lowest_eucled_id]['title'], wrap=True)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 4)\n",
    "    plt.imshow(np.load(f'depth_maps/{lowest_eucled_id}.npy'))\n",
    "    plt.title(f'Eucledian distance: {lowest_eucled:.3f}')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 5)\n",
    "    plt.imshow(load_np_image(data[lowest_manhattan_id]))\n",
    "    plt.title(data[lowest_manhattan_id]['title'], wrap=True)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 6)\n",
    "    plt.imshow(np.load(f'depth_maps/{lowest_manhattan_id}.npy'))\n",
    "    plt.title(f'Manhattan distance: {lowest_manhattan:.3f}')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 7)\n",
    "    plt.imshow(load_np_image(data[correlation_coefficient_id]))\n",
    "    plt.title(data[correlation_coefficient_id]['title'], wrap=True)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 8)\n",
    "    plt.imshow(np.load(f'depth_maps/{correlation_coefficient_id}.npy'))\n",
    "    plt.title(f'Correlation coef.: {correlation_coefficient:.3f}')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.show() \n",
    "    \n",
    "    plt.figure(figsize=(5, 8))\n",
    "    plt.subplot(4, 2, 1)\n",
    "    plt.imshow(load_np_image(data[structural_similarity_id]))\n",
    "    plt.title(data[structural_similarity_id]['title'], wrap=True)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 2)\n",
    "    plt.imshow(np.load(f'depth_maps/{structural_similarity_id}.npy'))\n",
    "    plt.title(f'Structural similarity: {structural_similarity:.3f}')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 3)\n",
    "    plt.imshow(load_np_image(data[jaccard_similarity_id]))\n",
    "    plt.title(data[jaccard_similarity_id]['title'], wrap=True)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 4)\n",
    "    plt.imshow(np.load(f'depth_maps/{jaccard_similarity_id}.npy'))\n",
    "    plt.title(f'Jaccard Similarity: {jaccard_similarity:.3f}')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 5)\n",
    "    plt.imshow(load_np_image(data[wasserstein_dist_id]))\n",
    "    plt.title(data[wasserstein_dist_id]['title'], wrap=True)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 6)\n",
    "    plt.imshow(np.load(f'depth_maps/{wasserstein_dist_id}.npy'))\n",
    "    plt.title(f'Wasserstein distance: {wasserstein_dist:.3f}')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 7)\n",
    "    plt.imshow(load_np_image(data[cosine_similarity_id]))\n",
    "    plt.title(data[cosine_similarity_id]['title'], wrap=True)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.subplot(4, 2, 8)\n",
    "    plt.imshow(np.load(f'depth_maps/{cosine_similarity_id}.npy'))\n",
    "    plt.title(f'Cosine similarity: {cosine_similarity:.3f}')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.show()      \n",
    "\n",
    "    bar.close() \n",
    "\n",
    "for id_ in data:\n",
    "    if data[id_]['artistName'] is not None and 'vermeer' in data[id_]['artistName'].lower():\n",
    "        plot_distances(id_)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hierarchical clustering\n",
    "\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, ward, average, single, complete\n",
    "\n",
    "\n",
    "distance_matrix = np.load('eucled_distance_matrix.npy')\n",
    "## for SSIM\n",
    "# distance_matrix = 1 - distance_matrix\n",
    "# np.fill_diagonal(distance_matrix, 0)\n",
    "\n",
    "\n",
    "condensed = squareform(distance_matrix)\n",
    "\n",
    "linked = ward(condensed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dendorgam\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linked, truncate_mode='lastp', p=50, color_threshold=9.5)  # Only show the last 50 merged clusters\n",
    "plt.axhline(y=9.5, color='r', linestyle='--')\n",
    "plt.ylabel('Razdalja')\n",
    "plt.xlabel('Grue (tevilo slik)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusers\n",
    "\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "max_clusters = 4\n",
    "\n",
    "# Cut the dendrogram and get the cluster labels\n",
    "cluster_labels = fcluster(linked, t=max_clusters, criterion='maxclust')\n",
    "print(np.unique(cluster_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for raw clustering\n",
    "\n",
    "depth_map_matrix = np.zeros((len(data), 10000))\n",
    "for i, id_ in enumerate(data):\n",
    "    depth_map = np.load(f'depth_maps_100/{id_}.npy')\n",
    "    depth_map_matrix[i] = depth_map.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(depth_map_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  hdbscan\n",
    "import hdbscan\n",
    "\n",
    "hdbscan = hdbscan.HDBSCAN(min_cluster_size=10, gen_min_span_tree=True)\n",
    "cluster_labels = hdbscan.fit_predict(depth_map_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#load distance-matrix\n",
    "distance_matrix = np.load('ssim_distance_matrix.npy')\n",
    "distance_matrix = 1 - distance_matrix\n",
    "np.fill_diagonal(distance_matrix, 0)\n",
    "\n",
    "#T-SNE\n",
    "tsne = TSNE(n_components=2,\n",
    "            metric='precomputed', \n",
    "            init='random', \n",
    "            random_state=1, )\n",
    "            ## exta parameters\n",
    "            # perplexity=50,\n",
    "            # early_exaggeration=30,\n",
    "            # learning_rate=200,\n",
    "            # n_iter=3000,\n",
    "            # n_iter_without_progress=300,\n",
    "            # min_grad_norm=1e-07,\n",
    "            # method='barnes_hut')\n",
    "embedded_space = tsne.fit_transform(distance_matrix)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(embedded_space[:, 0], embedded_space[:, 1], c=cluster_labels, alpha=0.6)  # Plotting all points\n",
    "plt.legend(*scatter.legend_elements(), title=\"Grue\")\n",
    "plt.xlabel('t-SNE dimenzija 1')\n",
    "plt.ylabel('t-SNE dimenzija 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MDS\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "#load distance-matrix\n",
    "distance_matrix = np.load('distance_matrix.npy')\n",
    "\n",
    "#MDS\n",
    "mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\n",
    "embedded_space = mds.fit_transform(distance_matrix)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(embedded_space[:, 0], embedded_space[:, 1], c=cluster_labels, cmap='viridis', alpha=0.6)  # Plotting all points\n",
    "plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "plt.title('t-SNE Graph of the Distance Matrix')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save distance matrix as CSV\n",
    "\n",
    "distance_matrix = np.load('eucled_distance_matrix.npy')\n",
    "\n",
    "#save as csv\n",
    "np.savetxt('distance_matrix.csv', distance_matrix, delimiter=',')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster explanation with silhouette score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "silhouette_vals = silhouette_samples(depth_map_matrix, cluster_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify an example with the highest silhouette score in each cluster\n",
    "\n",
    "unique_clusters = np.unique(cluster_labels)\n",
    "top_examples = {}\n",
    "\n",
    "for cluster in unique_clusters:\n",
    "    cluster_indices = np.where(cluster_labels == cluster)[0]\n",
    "\n",
    "    # Silhouette scores of samples in the current cluster\n",
    "    cluster_silhouette_vals = silhouette_vals[cluster_indices]\n",
    "   \n",
    "    top_indices = cluster_indices[np.argsort(-cluster_silhouette_vals)[:5]]\n",
    "    top_examples[cluster] = [(index, silhouette_vals[index]) for index in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot clusters with central examples\n",
    "\n",
    "keys = list(data.keys())\n",
    "fig = plt.figure(figsize=(6,9))\n",
    "i = 1\n",
    "first = True\n",
    "for ci, cluster in enumerate(top_examples.values()):\n",
    "    for (index, silhouette_val) in cluster:\n",
    "        painting = data[keys[index]]\n",
    "        depth_map = depth_map_matrix[index].reshape(100, 100)\n",
    "        plt.subplot(5, 4, i)\n",
    "        plt.imshow(depth_map, cmap='viridis')\n",
    "        if first:\n",
    "            plt.title(f'Grua {ci + 1}')\n",
    "            first = False\n",
    "        plt.axis('off')\n",
    "        i += 4\n",
    "    i = ci + 2\n",
    "    first = True\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of some paintings with their depth maps and cluster labels\n",
    "\n",
    "for i, id_ in enumerate(data):\n",
    "    if i > 2:\n",
    "        break\n",
    "    painting = data[id_]\n",
    "    print(painting['artistName'], ', ', painting['title'], ', ', painting['completitionYear'])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    image = load_np_image(painting)\n",
    "    plt.imshow(image)\n",
    "    plt.title(painting['title'])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    depth_map = predict_depth(image)\n",
    "    plt.imshow(depth_map, cmap='viridis')\n",
    "    plt.title(f'Grua: {cluster_labels[i]}')    \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE DEPTH MAPS WITH FACES\n",
    "\n",
    "import time\n",
    "\n",
    "def compare_faces_wtih_depth(painting, plot=False):\n",
    "    f = 17 #mm\n",
    "    sensor_height = 32 #mm\n",
    "    face_height = 185 #mm\n",
    "    faces_rf = ast.literal_eval(painting['retinaface'])\n",
    "    if len(faces_rf) == 0:\n",
    "        return -1, -1\n",
    "    points_x = []\n",
    "    points_y = []\n",
    "    points_z = []\n",
    "    depth_map_z = []\n",
    "    image = load_np_image(painting)\n",
    "\n",
    "    for i, face in enumerate(faces_rf):  \n",
    "        if len(face) == 0:\n",
    "            break\n",
    "        x1, y1, x2, y2 = faces_rf[face]['facial_area'][0], faces_rf[face]['facial_area'][1], faces_rf[face]['facial_area'][2], faces_rf[face]['facial_area'][3]\n",
    "        face_height_px = y2 - y1\n",
    "        image_height = image.shape[0]\n",
    "        d = (f * face_height * image_height) / (face_height_px * sensor_height)\n",
    "        points_x.append((x1+x2)/2)\n",
    "        points_y.append((y1+y2)/2)\n",
    "        points_z.append(d)\n",
    "        depth_map_z.append(faces_rf[face]['depth'])\n",
    "\n",
    "    if len(points_x) == 0:\n",
    "        return -1, -1\n",
    "\n",
    "    #points_x = np.array(points_x) / image.shape[1]\n",
    "    #points_y = np.array(points_y) / image.shape[0]\n",
    "\n",
    "    points_z = np.max(points_z) - np.array(points_z) # rotate coordinate system\n",
    "    points_z = (points_z - np.mean(points_z)) / np.std(points_z) # normalize\n",
    "    depth_map_z = np.array(depth_map_z)\n",
    "    depth_map_z = (depth_map_z - np.mean(depth_map_z)) / np.std(depth_map_z) # normalize\n",
    "\n",
    "    if (plot):\n",
    "        depth_map = predict_depth(image)\n",
    "        depth_map_norm = (depth_map - np.mean(depth_map)) / np.std(depth_map)\n",
    "        colormap_name = 'cool'\n",
    "        cmap = plt.cm.get_cmap(colormap_name)\n",
    "        copy = image.copy()\n",
    "        color_z = points_z + np.abs(np.min(points_z))\n",
    "        color_z = color_z / np.max(color_z)\n",
    "        \n",
    "        for i, face in enumerate(faces_rf):\n",
    "            x1, y1, x2, y2 = faces_rf[face]['facial_area'][0], faces_rf[face]['facial_area'][1], faces_rf[face]['facial_area'][2], faces_rf[face]['facial_area'][3]\n",
    "            \n",
    "            color = cmap(color_z[i])\n",
    "            copy = cv2.rectangle(copy, (x1, y1), (x2, y2), (color[0] *255, color[1] *255, color[2] *255), 2)\n",
    "            color = cmap(depth_map_z[i])\n",
    "            copy = cv2.rectangle(copy, (x1-5, y1-5), (x2+5, y2+5), (color[0] *255, color[1] *255, color[2] *255), 2)\n",
    "            #add text\n",
    "            #copy = cv2.putText(copy, str(round(points_z[i], 2)), (int((x1+x2)/2), int((y1+y2)/2)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "            #copy = cv2.putText(copy, str(round(depth_map_z[i], 2)), (int((x1+x2)/2), int((y1+y2)/2) + 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        plt.imshow(copy)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.show()\n",
    "\n",
    "        points_x = np.array(points_x) / image.shape[1] * depth_map.shape[1]\n",
    "        points_y = np.array(points_y) / image.shape[0] * depth_map.shape[0]\n",
    "\n",
    "        x, y = np.meshgrid(np.arange(depth_map.shape[1]), np.arange(depth_map.shape[0]))\n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes(projection='3d')\n",
    "        depth_normalized = (depth_map - np.min(depth_map)) / (np.max(depth_map) - np.min(depth_map))\n",
    "        ax.plot_surface(y, x, depth_map_norm, rstride=1, cstride=1, facecolors=cm.viridis(depth_normalized), linewidth=0, antialiased=False, shade=False, alpha=0.05)\n",
    "        plot = ax.scatter(points_y, points_x, points_z, c=points_z, s=150, cmap=colormap_name, alpha=1)\n",
    "        ax.view_init(azim=30, elev=80)\n",
    "        fig.colorbar(plot)\n",
    "        plt.show()\n",
    "\n",
    "    mse = np.sum(np.square(points_z - depth_map_z)) / len(points_z)\n",
    "    \n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comparison of depth maps with faces\n",
    "\n",
    "model_comparison_mse = {}\n",
    "\n",
    "for id_ in data:\n",
    "    n_faces = len(ast.literal_eval(data[id_]['retinaface']))\n",
    "    if n_faces > 1:\n",
    "        mse = compare_faces_wtih_depth(data[id_])\n",
    "        model_comparison_mse[id_] = mse\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by MSE\n",
    "\n",
    "sorted_mse = {k: v for k, v in sorted(model_comparison_mse.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method comparison examples\n",
    "\n",
    "keys = model_comparison_mse.keys()\n",
    "\n",
    "dobre_slike = [\n",
    "    'O Almoo dos Barqueiros',\n",
    "    'Forgotten People',\n",
    "    'Camille Monet and a Child in the Artists Garden in Argenteuil',\n",
    "    'Family feast'\n",
    "]\n",
    "\n",
    "count = 0\n",
    "for key in keys:\n",
    "    n_faces = len(ast.literal_eval(data[key]['retinaface']))\n",
    "    mse = model_comparison_mse[key]\n",
    "    # plot on graph where n_faces is x and mse is y\n",
    "    plt.scatter(n_faces, mse, c='mediumseagreen', alpha=0.2)\n",
    "    if data[key]['title'] in dobre_slike:\n",
    "        try:\n",
    "            print(data[key]['artistName'], data[key]['title'], data[key]['completitionYear'], n_faces, mse)\n",
    "        except KeyError:\n",
    "            print(data[key]['artistName'], data[key]['title'], 'None', n_faces, mse)\n",
    "        compare_faces_wtih_depth(data[key], plot=True)\n",
    "        if count == 0:\n",
    "            plt.annotate(data[key]['title'], (n_faces, mse), textcoords=\"offset points\", xytext=(5,2))\n",
    "        else:\n",
    "            plt.annotate(data[key]['title'], (n_faces, mse), textcoords=\"offset points\", xytext=(5,0))\n",
    "        plt.scatter(n_faces, mse, alpha=0.5, s=60, label=data[key]['title'], facecolors='none', edgecolors='black')\n",
    "        plt.scatter(n_faces, mse, c='mediumseagreen', alpha=0.2)\n",
    "        count += 1\n",
    "plt.xlabel('tevilo obrazov')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voxelize\n",
    "\n",
    "\n",
    "def voxelize_square(depth_map, resolution):\n",
    "    image_range = np.max(depth_map) - np.min(depth_map)\n",
    "    depth_norm = (((depth_map - np.min(depth_map)) / image_range) * resolution).astype(np.uint8)\n",
    "    depth_norm = cv2.resize(depth_norm, (resolution, resolution), interpolation=cv2.INTER_NEAREST)\n",
    "    points_x = []\n",
    "    points_y = []\n",
    "    points_z = []\n",
    "    for d in range(np.max(depth_norm), np.min(depth_norm), -1):\n",
    "        indices = np.where(depth_norm >= d)\n",
    "        points_x.append(indices[0])\n",
    "        points_y.append(indices[1])\n",
    "        points_z.append(depth_norm[indices])\n",
    "    points_x = np.concatenate(points_x)\n",
    "    points_y = np.concatenate(points_y)\n",
    "    points_z = np.concatenate(points_z)\n",
    "    A = np.column_stack((points_x, points_y, np.ones_like(points_x)))\n",
    "    coefficients, residuals, _, _ = np.linalg.lstsq(A, points_z, rcond=None)\n",
    "    a, b, c = coefficients\n",
    "    normal = np.array([a, b, -1]) / np.linalg.norm(np.array([a, b, -1]))\n",
    "    normal_z0 = np.array([0, 0, 1])\n",
    "    angle = np.arccos(np.abs(np.dot(normal, normal_z0)))\n",
    "    \n",
    "    return angle, np.degrees(angle)\n",
    "\n",
    "def voxelize_square_no_depth(depth_map, resolution):\n",
    "    image_range = np.max(depth_map) - np.min(depth_map)\n",
    "    depth_norm = (((depth_map - np.min(depth_map)) / image_range) * resolution).astype(np.uint8)\n",
    "    depth_norm = cv2.resize(depth_norm, (resolution, resolution), interpolation=cv2.INTER_NEAREST)\n",
    "    points_x = []\n",
    "    points_y = []\n",
    "    points_z = []\n",
    "    for d in range(np.max(depth_norm), np.min(depth_norm), -1):\n",
    "        indices = np.where(depth_norm == d)\n",
    "        points_x.append(indices[0])\n",
    "        points_y.append(indices[1])\n",
    "        points_z.append(depth_norm[indices])\n",
    "    points_x = np.concatenate(points_x)\n",
    "    points_y = np.concatenate(points_y)\n",
    "    points_z = np.concatenate(points_z)\n",
    "    A = np.column_stack((points_x, points_y, np.ones_like(points_x)))\n",
    "    coefficients, residuals, _, _ = np.linalg.lstsq(A, points_z, rcond=None)\n",
    "    a, b, c = coefficients\n",
    "    normal = np.array([a, b, -1]) / np.linalg.norm(np.array([a, b, -1]))\n",
    "    normal_z0 = np.array([0, 0, 1])\n",
    "    angle = np.arccos(np.abs(np.dot(normal, normal_z0)))\n",
    "    \n",
    "    return angle, np.degrees(angle)\n",
    "\n",
    "\n",
    "def voxelize_whole_ratio(depth_map, height, width, resolution=100):\n",
    "    shrink_ratio = resolution / np.min(depth_map.shape)\n",
    "    depth_ratio = resolution / np.min([width, height])\n",
    "    depth_norm = cv2.resize(depth_map, (0, 0), fx=shrink_ratio, fy=shrink_ratio, interpolation=cv2.INTER_NEAREST)\n",
    "    depth_norm = ((depth_norm - np.min(depth_norm)) * depth_ratio).astype(np.uint64) \n",
    "    points_x = []\n",
    "    points_y = []\n",
    "    points_z = []\n",
    "    for d in range(np.max(depth_norm), np.min(depth_norm), -1):\n",
    "        indices = np.where(depth_norm >= d)\n",
    "        points_x.append(indices[0])\n",
    "        points_y.append(indices[1])\n",
    "        points_z.append(depth_norm[indices])\n",
    "    points_x = np.concatenate(points_x)\n",
    "    points_y = np.concatenate(points_y)\n",
    "    points_z = np.concatenate(points_z)\n",
    "    A = np.column_stack((points_x, points_y, np.ones_like(points_x)))\n",
    "    coefficients, residuals, _, _ = np.linalg.lstsq(A, points_z, rcond=None)\n",
    "    a, b, c = coefficients\n",
    "    normal = np.array([a, b, -1]) / np.linalg.norm(np.array([a, b, -1]))\n",
    "    normal_z0 = np.array([0, 0, 1])\n",
    "    angle = np.arccos(np.abs(np.dot(normal, normal_z0)))\n",
    "    \n",
    "    return angle, np.degrees(angle)\n",
    "\n",
    "def voxelize_whole_ratio_no_depth(depth_map, height, width, resolution=100):\n",
    "    shrink_ratio = resolution / np.min(depth_map.shape)\n",
    "    depth_ratio = resolution / np.min([width, height])\n",
    "    depth_norm = cv2.resize(depth_map, (0, 0), fx=shrink_ratio, fy=shrink_ratio, interpolation=cv2.INTER_NEAREST)\n",
    "    depth_norm = ((depth_norm - np.min(depth_norm)) * depth_ratio).astype(np.uint64) \n",
    "    points_x = []\n",
    "    points_y = []\n",
    "    points_z = []\n",
    "    for d in range(np.max(depth_norm), np.min(depth_norm), -1):\n",
    "        indices = np.where(depth_norm == d)\n",
    "        points_x.append(indices[0])\n",
    "        points_y.append(indices[1])\n",
    "        points_z.append(depth_norm[indices])\n",
    "    points_x = np.concatenate(points_x)\n",
    "    points_y = np.concatenate(points_y)\n",
    "    points_z = np.concatenate(points_z)\n",
    "    A = np.column_stack((points_x, points_y, np.ones_like(points_x)))\n",
    "    coefficients, residuals, _, _ = np.linalg.lstsq(A, points_z, rcond=None)\n",
    "    a, b, c = coefficients\n",
    "    normal = np.array([a, b, -1]) / np.linalg.norm(np.array([a, b, -1]))\n",
    "    normal_z0 = np.array([0, 0, 1])\n",
    "    angle = np.arccos(np.abs(np.dot(normal, normal_z0)))\n",
    "    \n",
    "    return angle, np.degrees(angle)\n",
    "\n",
    "def voxelize_no_back(depth_map, height, width, resolution=100):\n",
    "    shrink_ratio = resolution / np.min(depth_map.shape)\n",
    "    depth_ratio = resolution / np.min([width, height])\n",
    "    depth_norm = cv2.resize(depth_map, (0, 0), fx=shrink_ratio, fy=shrink_ratio, interpolation=cv2.INTER_NEAREST)\n",
    "    depth_norm = ((depth_norm - np.min(depth_norm)) * depth_ratio).astype(np.uint64) \n",
    "    points_x = []\n",
    "    points_y = []\n",
    "    points_z = []\n",
    "    for d in range(int(np.max(depth_norm)), int(np.min(depth_norm)) + 1, -1):\n",
    "        indices = np.where(depth_norm >= d)\n",
    "        points_x.append(indices[0])\n",
    "        points_y.append(indices[1])\n",
    "        points_z.append(depth_norm[indices])\n",
    "    points_x = np.concatenate(points_x)\n",
    "    points_y = np.concatenate(points_y)\n",
    "    points_z = np.concatenate(points_z)\n",
    "    A = np.column_stack((points_x, points_y, np.ones_like(points_x)))\n",
    "    coefficients, residuals, _, _ = np.linalg.lstsq(A, points_z, rcond=None)\n",
    "    a, b, c = coefficients\n",
    "    normal = np.array([a, b, -1]) / np.linalg.norm(np.array([a, b, -1]))\n",
    "    normal_z0 = np.array([0, 0, 1])\n",
    "    angle = np.arccos(np.abs(np.dot(normal, normal_z0)))\n",
    "    \n",
    "    return angle, np.degrees(angle)\n",
    "\n",
    "def voxelize_no_back_no_depth(depth_map, height, width, resolution=100):\n",
    "    shrink_ratio = resolution / np.min(depth_map.shape)\n",
    "    depth_ratio = resolution / np.min([width, height])\n",
    "    depth_norm = cv2.resize(depth_map, (0, 0), fx=shrink_ratio, fy=shrink_ratio, interpolation=cv2.INTER_NEAREST)\n",
    "    depth_norm = ((depth_norm - np.min(depth_norm)) * depth_ratio).astype(np.uint64) \n",
    "    points_x = []\n",
    "    points_y = []\n",
    "    points_z = []\n",
    "    for d in range(int(np.max(depth_norm)), int(np.min(depth_norm)) + 1, -1):\n",
    "        indices = np.where(depth_norm == d)\n",
    "        points_x.append(indices[0])\n",
    "        points_y.append(indices[1])\n",
    "        points_z.append(depth_norm[indices])\n",
    "    points_x = np.concatenate(points_x)\n",
    "    points_y = np.concatenate(points_y)\n",
    "    points_z = np.concatenate(points_z)\n",
    "    A = np.column_stack((points_x, points_y, np.ones_like(points_x)))\n",
    "    coefficients, residuals, _, _ = np.linalg.lstsq(A, points_z, rcond=None)\n",
    "    a, b, c = coefficients\n",
    "    normal = np.array([a, b, -1]) / np.linalg.norm(np.array([a, b, -1]))\n",
    "    normal_z0 = np.array([0, 0, 1])\n",
    "    angle = np.arccos(np.abs(np.dot(normal, normal_z0)))\n",
    "    \n",
    "    return angle, np.degrees(angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize results\n",
    "\n",
    "def show(painting):\n",
    "    image = load_np_image(painting)\n",
    "    depth_map = predict_depth(image)\n",
    "    print(painting['artistName'], ' - ', painting['title'], ' - ',painting['completitionYear'])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(depth_map)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "with open('image_data.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "    count = 0\n",
    "    for id_ in data:\n",
    "        year = data[id_]['completitionYear']\n",
    "        if year == None:\n",
    "            continue\n",
    "\n",
    "        if year > 1700 and year < 1800:\n",
    "            show(data[id_])\n",
    "\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
